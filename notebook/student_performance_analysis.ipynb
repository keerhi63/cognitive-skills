{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Cognitive Skills & Student Performance Analysis\n",
        "\n",
        "This notebook analyzes the relationship between cognitive skills and student performance, builds ML models for prediction, and performs clustering analysis to identify learning personas.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Data Generation and Loading](#data-generation)\n",
        "2. [Exploratory Data Analysis](#eda)\n",
        "3. [Correlation Analysis](#correlation)\n",
        "4. [Machine Learning Model](#ml-model)\n",
        "5. [Student Clustering](#clustering)\n",
        "6. [Key Insights and Findings](#insights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Data Generation and Loading {#data-generation}\n",
        "\n",
        "First, let's generate synthetic student data with realistic cognitive skills and performance metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic student data\n",
        "def generate_student_data(n_students=200):\n",
        "    \"\"\"Generate synthetic student data with cognitive skills and performance metrics\"\"\"\n",
        "    \n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # Student IDs and names\n",
        "    student_ids = [f\"STU{i:03d}\" for i in range(1, n_students + 1)]\n",
        "    \n",
        "    # Generate names\n",
        "    first_names = [\n",
        "        \"Alex\", \"Jordan\", \"Taylor\", \"Morgan\", \"Casey\", \"Riley\", \"Avery\", \"Quinn\",\n",
        "        \"Blake\", \"Cameron\", \"Drew\", \"Emery\", \"Finley\", \"Hayden\", \"Jamie\", \"Kendall\",\n",
        "        \"Lane\", \"Parker\", \"Reese\", \"Sage\", \"Skyler\", \"Tatum\", \"River\", \"Phoenix\",\n",
        "        \"Sam\", \"Charlie\", \"Dakota\", \"Emerson\", \"Frankie\", \"Gray\", \"Harper\", \"Indigo\",\n",
        "        \"Jules\", \"Kai\", \"Lennox\", \"Marlowe\", \"Noah\", \"Ocean\", \"Peyton\", \"Rowan\"\n",
        "    ]\n",
        "    \n",
        "    last_names = [\n",
        "        \"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\",\n",
        "        \"Rodriguez\", \"Martinez\", \"Hernandez\", \"Lopez\", \"Gonzalez\", \"Wilson\", \"Anderson\", \"Thomas\",\n",
        "        \"Taylor\", \"Moore\", \"Jackson\", \"Martin\", \"Lee\", \"Perez\", \"Thompson\", \"White\",\n",
        "        \"Harris\", \"Sanchez\", \"Clark\", \"Ramirez\", \"Lewis\", \"Robinson\", \"Walker\", \"Young\",\n",
        "        \"Allen\", \"King\", \"Wright\", \"Scott\", \"Torres\", \"Nguyen\", \"Hill\", \"Flores\"\n",
        "    ]\n",
        "    \n",
        "    names = [f\"{np.random.choice(first_names)} {np.random.choice(last_names)}\" for _ in range(n_students)]\n",
        "    \n",
        "    # Generate classes (grades 9-12)\n",
        "    classes = np.random.choice([9, 10, 11, 12], n_students, p=[0.25, 0.25, 0.25, 0.25])\n",
        "    \n",
        "    # Generate cognitive skills (0-100 scale)\n",
        "    # Create some correlation between skills\n",
        "    base_skill = np.random.normal(70, 15, n_students)\n",
        "    base_skill = np.clip(base_skill, 20, 95)\n",
        "    \n",
        "    # Comprehension (correlated with base skill)\n",
        "    comprehension = base_skill + np.random.normal(0, 8, n_students)\n",
        "    comprehension = np.clip(comprehension, 20, 100)\n",
        "    \n",
        "    # Attention (slightly different distribution)\n",
        "    attention = base_skill + np.random.normal(0, 10, n_students)\n",
        "    attention = np.clip(attention, 15, 100)\n",
        "    \n",
        "    # Focus (correlated with attention)\n",
        "    focus = attention + np.random.normal(0, 6, n_students)\n",
        "    focus = np.clip(focus, 20, 100)\n",
        "    \n",
        "    # Retention (correlated with comprehension)\n",
        "    retention = comprehension + np.random.normal(0, 7, n_students)\n",
        "    retention = np.clip(retention, 25, 100)\n",
        "    \n",
        "    # Engagement time (minutes per week, correlated with attention)\n",
        "    engagement_time = (attention * 0.8 + np.random.normal(0, 15, n_students)).astype(int)\n",
        "    engagement_time = np.clip(engagement_time, 30, 300)\n",
        "    \n",
        "    # Assessment score (correlated with all cognitive skills)\n",
        "    # Weight the skills differently\n",
        "    assessment_score = (\n",
        "        comprehension * 0.3 +\n",
        "        attention * 0.25 +\n",
        "        focus * 0.2 +\n",
        "        retention * 0.25 +\n",
        "        np.random.normal(0, 5, n_students)\n",
        "    )\n",
        "    assessment_score = np.clip(assessment_score, 0, 100)\n",
        "    \n",
        "    # Create DataFrame\n",
        "    data = {\n",
        "        'student_id': student_ids,\n",
        "        'name': names,\n",
        "        'class': classes,\n",
        "        'comprehension': np.round(comprehension, 1),\n",
        "        'attention': np.round(attention, 1),\n",
        "        'focus': np.round(focus, 1),\n",
        "        'retention': np.round(retention, 1),\n",
        "        'assessment_score': np.round(assessment_score, 1),\n",
        "        'engagement_time': engagement_time\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Add some learning personas based on skill patterns\n",
        "    def assign_persona(row):\n",
        "        if row['comprehension'] > 80 and row['attention'] > 80:\n",
        "            return 'High Achiever'\n",
        "        elif row['attention'] < 50 and row['focus'] < 50:\n",
        "            return 'Distracted Learner'\n",
        "        elif row['retention'] > 85 and row['comprehension'] > 75:\n",
        "            return 'Analytical Thinker'\n",
        "        elif row['engagement_time'] > 200 and row['attention'] > 70:\n",
        "            return 'Engaged Explorer'\n",
        "        elif row['comprehension'] < 60 and row['retention'] < 60:\n",
        "            return 'Struggling Student'\n",
        "        else:\n",
        "            return 'Balanced Learner'\n",
        "    \n",
        "    df['learning_persona'] = df.apply(assign_persona, axis=1)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Generate the dataset\n",
        "print(\"Generating synthetic student dataset...\")\n",
        "student_df = generate_student_data(200)\n",
        "\n",
        "# Save to CSV\n",
        "student_df.to_csv('../data/student_data.csv', index=False)\n",
        "print(f\"Dataset saved with {len(student_df)} students\")\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"\\nDataset Overview:\")\n",
        "print(f\"Shape: {student_df.shape}\")\n",
        "print(f\"\\nColumns: {list(student_df.columns)}\")\n",
        "print(f\"\\nLearning Personas Distribution:\")\n",
        "print(student_df['learning_persona'].value_counts())\n",
        "print(f\"\\nClass Distribution:\")\n",
        "print(student_df['class'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample data\n",
        "print(\"Sample Data:\")\n",
        "print(student_df.head(10))\n",
        "\n",
        "# Display correlation matrix\n",
        "print(\"\\nCorrelation Matrix (Cognitive Skills vs Assessment Score):\")\n",
        "correlation_cols = ['comprehension', 'attention', 'focus', 'retention', 'assessment_score']\n",
        "correlation_matrix = student_df[correlation_cols].corr()\n",
        "print(correlation_matrix.round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Exploratory Data Analysis {#eda}\n",
        "\n",
        "Let's explore the dataset to understand the distribution of cognitive skills and performance metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive EDA plots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Cognitive Skills & Performance Distribution Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Assessment Score Distribution\n",
        "axes[0, 0].hist(student_df['assessment_score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Assessment Score Distribution')\n",
        "axes[0, 0].set_xlabel('Assessment Score')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].axvline(student_df['assessment_score'].mean(), color='red', linestyle='--', \n",
        "                   label=f'Mean: {student_df[\"assessment_score\"].mean():.1f}')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# 2. Cognitive Skills Box Plot\n",
        "skills_data = [student_df['comprehension'], student_df['attention'], \n",
        "               student_df['focus'], student_df['retention']]\n",
        "skills_labels = ['Comprehension', 'Attention', 'Focus', 'Retention']\n",
        "box_plot = axes[0, 1].boxplot(skills_data, labels=skills_labels, patch_artist=True)\n",
        "colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
        "for patch, color in zip(box_plot['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "axes[0, 1].set_title('Cognitive Skills Distribution')\n",
        "axes[0, 1].set_ylabel('Score')\n",
        "\n",
        "# 3. Learning Personas Distribution\n",
        "persona_counts = student_df['learning_persona'].value_counts()\n",
        "axes[0, 2].pie(persona_counts.values, labels=persona_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "axes[0, 2].set_title('Learning Personas Distribution')\n",
        "\n",
        "# 4. Class Distribution\n",
        "class_counts = student_df['class'].value_counts().sort_index()\n",
        "axes[1, 0].bar(class_counts.index, class_counts.values, color='lightsteelblue', edgecolor='black')\n",
        "axes[1, 0].set_title('Students by Class/Grade')\n",
        "axes[1, 0].set_xlabel('Class')\n",
        "axes[1, 0].set_ylabel('Number of Students')\n",
        "\n",
        "# 5. Engagement Time vs Assessment Score\n",
        "scatter = axes[1, 1].scatter(student_df['engagement_time'], student_df['assessment_score'], \n",
        "                            c=student_df['assessment_score'], cmap='viridis', alpha=0.6)\n",
        "axes[1, 1].set_title('Engagement Time vs Assessment Score')\n",
        "axes[1, 1].set_xlabel('Engagement Time (minutes/week)')\n",
        "axes[1, 1].set_ylabel('Assessment Score')\n",
        "plt.colorbar(scatter, ax=axes[1, 1], label='Assessment Score')\n",
        "\n",
        "# 6. Skills Correlation Heatmap\n",
        "correlation_matrix = student_df[['comprehension', 'attention', 'focus', 'retention', 'assessment_score']].corr()\n",
        "im = axes[1, 2].imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "axes[1, 2].set_xticks(range(len(correlation_matrix.columns)))\n",
        "axes[1, 2].set_yticks(range(len(correlation_matrix.columns)))\n",
        "axes[1, 2].set_xticklabels(correlation_matrix.columns, rotation=45)\n",
        "axes[1, 2].set_yticklabels(correlation_matrix.columns)\n",
        "axes[1, 2].set_title('Skills Correlation Heatmap')\n",
        "\n",
        "# Add correlation values to heatmap\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(len(correlation_matrix.columns)):\n",
        "        text = axes[1, 2].text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',\n",
        "                              ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"Summary Statistics:\")\n",
        "print(student_df.describe().round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Correlation Analysis {#correlation}\n",
        "\n",
        "Let's analyze the correlations between cognitive skills and performance metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed correlation analysis\n",
        "correlation_cols = ['comprehension', 'attention', 'focus', 'retention', 'assessment_score', 'engagement_time']\n",
        "correlation_matrix = student_df[correlation_cols].corr()\n",
        "\n",
        "# Create a more detailed correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}, fmt='.3f')\n",
        "plt.title('Detailed Correlation Matrix: Cognitive Skills & Performance', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze correlations with assessment score\n",
        "assessment_correlations = correlation_matrix['assessment_score'].drop('assessment_score').sort_values(ascending=False)\n",
        "print(\"Correlation with Assessment Score (sorted by strength):\")\n",
        "print(assessment_correlations.round(3))\n",
        "\n",
        "# Create scatter plots for each skill vs assessment score\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Individual Cognitive Skills vs Assessment Score', fontsize=16, fontweight='bold')\n",
        "\n",
        "skills = ['comprehension', 'attention', 'focus', 'retention']\n",
        "colors = ['skyblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
        "\n",
        "for i, (skill, color) in enumerate(zip(skills, colors)):\n",
        "    row, col = i // 2, i % 2\n",
        "    axes[row, col].scatter(student_df[skill], student_df['assessment_score'], \n",
        "                          alpha=0.6, color=color, edgecolor='black', s=50)\n",
        "    \n",
        "    # Add trend line\n",
        "    z = np.polyfit(student_df[skill], student_df['assessment_score'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[row, col].plot(student_df[skill], p(student_df[skill]), \"r--\", alpha=0.8, linewidth=2)\n",
        "    \n",
        "    # Calculate and display correlation\n",
        "    corr = student_df[skill].corr(student_df['assessment_score'])\n",
        "    axes[row, col].set_title(f'{skill.title()} vs Assessment Score\\n(r = {corr:.3f})')\n",
        "    axes[row, col].set_xlabel(f'{skill.title()} Score')\n",
        "    axes[row, col].set_ylabel('Assessment Score')\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Machine Learning Model {#ml-model}\n",
        "\n",
        "Let's build ML models to predict assessment scores based on cognitive skills.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for ML models\n",
        "X = student_df[['comprehension', 'attention', 'focus', 'retention', 'engagement_time', 'class']]\n",
        "y = student_df['assessment_score']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "# Train multiple models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "model_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    train_r2 = r2_score(y_train, y_pred_train)\n",
        "    test_r2 = r2_score(y_test, y_pred_test)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "    \n",
        "    model_results[name] = {\n",
        "        'model': model,\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'train_mae': train_mae,\n",
        "        'test_mae': test_mae,\n",
        "        'y_pred_test': y_pred_test\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"  Training R²: {train_r2:.3f}\")\n",
        "    print(f\"  Test R²: {test_r2:.3f}\")\n",
        "    print(f\"  Training RMSE: {train_rmse:.3f}\")\n",
        "    print(f\"  Test RMSE: {test_rmse:.3f}\")\n",
        "    print(f\"  Training MAE: {train_mae:.3f}\")\n",
        "    print(f\"  Test MAE: {test_mae:.3f}\")\n",
        "\n",
        "# Visualize model performance\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, (name, results) in enumerate(model_results.items()):\n",
        "    axes[i].scatter(y_test, results['y_pred_test'], alpha=0.6, s=50)\n",
        "    axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    axes[i].set_xlabel('Actual Assessment Score')\n",
        "    axes[i].set_ylabel('Predicted Assessment Score')\n",
        "    axes[i].set_title(f'{name}\\nR² = {results[\"test_r2\"]:.3f}, RMSE = {results[\"test_rmse\"]:.3f}')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance for Random Forest\n",
        "if 'Random Forest' in model_results:\n",
        "    rf_model = model_results['Random Forest']['model']\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': rf_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
        "    plt.title('Feature Importance - Random Forest Model', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nFeature Importance (Random Forest):\")\n",
        "    print(feature_importance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Student Clustering {#clustering}\n",
        "\n",
        "Let's cluster students into learning personas using K-means clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for clustering\n",
        "clustering_features = ['comprehension', 'attention', 'focus', 'retention', 'engagement_time', 'assessment_score']\n",
        "X_cluster = student_df[clustering_features]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_cluster_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "# Determine optimal number of clusters using elbow method\n",
        "inertias = []\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_cluster_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Perform K-means clustering with k=6 (based on our predefined personas)\n",
        "kmeans = KMeans(n_clusters=6, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(X_cluster_scaled)\n",
        "\n",
        "# Add cluster labels to dataframe\n",
        "student_df['cluster'] = cluster_labels\n",
        "\n",
        "# Analyze clusters\n",
        "cluster_analysis = student_df.groupby('cluster')[clustering_features].mean().round(2)\n",
        "print(\"Cluster Analysis - Average Values:\")\n",
        "print(cluster_analysis)\n",
        "\n",
        "# Compare with predefined personas\n",
        "persona_cluster_mapping = student_df.groupby(['learning_persona', 'cluster']).size().unstack(fill_value=0)\n",
        "print(\"\\nPersona vs Cluster Mapping:\")\n",
        "print(persona_cluster_mapping)\n",
        "\n",
        "# Visualize clusters\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Student Clusters Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Comprehension vs Attention\n",
        "scatter = axes[0, 0].scatter(student_df['comprehension'], student_df['attention'], \n",
        "                            c=student_df['cluster'], cmap='tab10', alpha=0.7, s=60)\n",
        "axes[0, 0].set_xlabel('Comprehension')\n",
        "axes[0, 0].set_ylabel('Attention')\n",
        "axes[0, 0].set_title('Comprehension vs Attention (Clusters)')\n",
        "plt.colorbar(scatter, ax=axes[0, 0], label='Cluster')\n",
        "\n",
        "# 2. Focus vs Retention\n",
        "scatter = axes[0, 1].scatter(student_df['focus'], student_df['retention'], \n",
        "                            c=student_df['cluster'], cmap='tab10', alpha=0.7, s=60)\n",
        "axes[0, 1].set_xlabel('Focus')\n",
        "axes[0, 1].set_ylabel('Retention')\n",
        "axes[0, 1].set_title('Focus vs Retention (Clusters)')\n",
        "plt.colorbar(scatter, ax=axes[0, 1], label='Cluster')\n",
        "\n",
        "# 3. Engagement Time vs Assessment Score\n",
        "scatter = axes[1, 0].scatter(student_df['engagement_time'], student_df['assessment_score'], \n",
        "                            c=student_df['cluster'], cmap='tab10', alpha=0.7, s=60)\n",
        "axes[1, 0].set_xlabel('Engagement Time')\n",
        "axes[1, 0].set_ylabel('Assessment Score')\n",
        "axes[1, 0].set_title('Engagement Time vs Assessment Score (Clusters)')\n",
        "plt.colorbar(scatter, ax=axes[1, 0], label='Cluster')\n",
        "\n",
        "# 4. Cluster distribution\n",
        "cluster_counts = student_df['cluster'].value_counts().sort_index()\n",
        "axes[1, 1].bar(cluster_counts.index, cluster_counts.values, color='lightsteelblue', edgecolor='black')\n",
        "axes[1, 1].set_xlabel('Cluster')\n",
        "axes[1, 1].set_ylabel('Number of Students')\n",
        "axes[1, 1].set_title('Cluster Distribution')\n",
        "axes[1, 1].set_xticks(range(6))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create cluster profiles\n",
        "print(\"\\nCluster Profiles:\")\n",
        "for cluster_id in range(6):\n",
        "    cluster_data = student_df[student_df['cluster'] == cluster_id]\n",
        "    print(f\"\\nCluster {cluster_id} ({len(cluster_data)} students):\")\n",
        "    print(f\"  Average Comprehension: {cluster_data['comprehension'].mean():.1f}\")\n",
        "    print(f\"  Average Attention: {cluster_data['attention'].mean():.1f}\")\n",
        "    print(f\"  Average Focus: {cluster_data['focus'].mean():.1f}\")\n",
        "    print(f\"  Average Retention: {cluster_data['retention'].mean():.1f}\")\n",
        "    print(f\"  Average Assessment Score: {cluster_data['assessment_score'].mean():.1f}\")\n",
        "    print(f\"  Average Engagement Time: {cluster_data['engagement_time'].mean():.1f}\")\n",
        "    print(f\"  Most Common Persona: {cluster_data['learning_persona'].mode().iloc[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Key Insights and Findings {#insights}\n",
        "\n",
        "Let's summarize the key findings from our analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive insights\n",
        "print(\"=\" * 60)\n",
        "print(\"COGNITIVE SKILLS & STUDENT PERFORMANCE ANALYSIS - KEY FINDINGS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Overall Performance Statistics\n",
        "print(\"\\n1. OVERALL PERFORMANCE STATISTICS:\")\n",
        "print(f\"   • Total Students Analyzed: {len(student_df)}\")\n",
        "print(f\"   • Average Assessment Score: {student_df['assessment_score'].mean():.1f} ± {student_df['assessment_score'].std():.1f}\")\n",
        "print(f\"   • Score Range: {student_df['assessment_score'].min():.1f} - {student_df['assessment_score'].max():.1f}\")\n",
        "\n",
        "# 2. Cognitive Skills Analysis\n",
        "print(\"\\n2. COGNITIVE SKILLS ANALYSIS:\")\n",
        "skills_stats = student_df[['comprehension', 'attention', 'focus', 'retention']].describe()\n",
        "for skill in ['comprehension', 'attention', 'focus', 'retention']:\n",
        "    mean_val = skills_stats.loc['mean', skill]\n",
        "    std_val = skills_stats.loc['std', skill]\n",
        "    print(f\"   • {skill.title()}: {mean_val:.1f} ± {std_val:.1f}\")\n",
        "\n",
        "# 3. Correlation Insights\n",
        "print(\"\\n3. CORRELATION INSIGHTS:\")\n",
        "correlation_with_score = student_df[['comprehension', 'attention', 'focus', 'retention', 'engagement_time']].corrwith(student_df['assessment_score']).sort_values(ascending=False)\n",
        "for skill, corr in correlation_with_score.items():\n",
        "    strength = \"Strong\" if abs(corr) > 0.7 else \"Moderate\" if abs(corr) > 0.5 else \"Weak\"\n",
        "    print(f\"   • {skill.title()}: {corr:.3f} ({strength} correlation)\")\n",
        "\n",
        "# 4. Learning Personas Distribution\n",
        "print(\"\\n4. LEARNING PERSONAS DISTRIBUTION:\")\n",
        "persona_counts = student_df['learning_persona'].value_counts()\n",
        "for persona, count in persona_counts.items():\n",
        "    percentage = (count / len(student_df)) * 100\n",
        "    print(f\"   • {persona}: {count} students ({percentage:.1f}%)\")\n",
        "\n",
        "# 5. Model Performance Summary\n",
        "print(\"\\n5. MACHINE LEARNING MODEL PERFORMANCE:\")\n",
        "if 'Random Forest' in model_results:\n",
        "    rf_results = model_results['Random Forest']\n",
        "    print(f\"   • Best Model: Random Forest\")\n",
        "    print(f\"   • R² Score: {rf_results['test_r2']:.3f}\")\n",
        "    print(f\"   • RMSE: {rf_results['test_rmse']:.3f}\")\n",
        "    print(f\"   • MAE: {rf_results['test_mae']:.3f}\")\n",
        "\n",
        "# 6. Key Recommendations\n",
        "print(\"\\n6. KEY RECOMMENDATIONS:\")\n",
        "print(\"   • Focus on comprehension and retention skills as they show strongest correlation with performance\")\n",
        "print(\"   • Implement targeted interventions for 'Struggling Students' and 'Distracted Learners'\")\n",
        "print(\"   • Leverage 'High Achievers' and 'Analytical Thinkers' as peer mentors\")\n",
        "print(\"   • Monitor engagement time as it correlates with attention and performance\")\n",
        "print(\"   • Use ML models to predict at-risk students early for intervention\")\n",
        "\n",
        "# 7. Class-wise Analysis\n",
        "print(\"\\n7. CLASS-WISE PERFORMANCE:\")\n",
        "class_performance = student_df.groupby('class')['assessment_score'].agg(['mean', 'std', 'count']).round(2)\n",
        "for class_id, stats in class_performance.iterrows():\n",
        "    print(f\"   • Class {class_id}: {stats['mean']:.1f} ± {stats['std']:.1f} ({stats['count']} students)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ANALYSIS COMPLETE - Ready for Dashboard Implementation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Save the final dataset with all analysis\n",
        "student_df.to_csv('../data/student_data_with_analysis.csv', index=False)\n",
        "print(f\"\\nFinal dataset with analysis saved to: ../data/student_data_with_analysis.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
